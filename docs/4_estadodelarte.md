Estado del arte
===============

El presente capítulo se basa en una recopilación exhaustiva de la bibliografía
disponible acerca de estudios de caso de evaluaciones de IDE. Dicha literatura
no es abundante y, como conjunto, se caracteriza por no presentar un enfoque
teórico común, aunque sí se apoya en una serie de definiciones similares
referidas a conceptos tales como: evaluación, indicadores, sistemas complejos y
redes, que ya se desarrollaron en el marco teórico precedente.

Las distintas evaluaciones de IDE analizadas, presentan un amplio uso del
concepto de evaluación multicriterio, ya que el mismo es adaptable a las
distintas perspectivas que se pueden tener sobre una IDE.

##### Figura 1 - Marco de evaluación multicriterio de IDE

![Figura 1. Marco de evaluación multicriterio de IDE](media/f74c3f4765996d7e215a61fa216693bb.png)
##### *Fuente: elaboración propia en base a Grus, Crompvoets y Bregt (2007).*

En particular, en el presente estado del arte, se han tomado en cuenta las
experiencias de la Infraestructura para la Información Espacial en Europa
(INSPIRE por su sigla en inglés), de la Coalición de Organizaciones
Geoespaciales (COGO por su sigla en inglés), de la Red Temática con base
internet de Infraestructuras de Datos Espaciales (eSDI-Net+ por su sigla en
inglés), del Comité Regional de las Naciones Unidas sobre la Gestión Global de
Información Geoespacial para las Américas (UN-GGIM:Américas), del Índice de
aptitud Clearinghouse, del Índice de Alistamiento, del Plan Estratégico de
desarrollo de la IDE de Holanda (GIDEON), de la Infraestructura de Datos
Espaciales de Polonia (PSDI por su sigla en inglés) y de la Infraestructura de
Datos Espaciales de Cataluña (IDEC).

### Monitoreo y Reporte de INSPIRE

La evaluación desarrollada por INSPIRE, documentada en Jiménez-Calderón,
Yépez-Campoverde y Vázquez-Hoehne (2017), en Castelein y Manso Callejo (2010) y
en Masser (2017), busca medir el grado de cumplimiento de los estándares
establecidos, en las distintas IDE europeas.

INSPIRE, iniciativa aprobada en 2007 por el Parlamento Europeo, tiene por fin
generar las reglas generales necesarias para establecer una IDE en la Unión
Europea, sobre la base de las IDE de los países miembro.

Así, permite evaluar a las distintas IDE nacionales de Europa en materia de
implementación de las reglas de metadatos, servicios de red, uso del modelo de
geoportal INSPIRE, interoperabilidad de datos, grado en que se comparte la
información geográfica, servicios, monitoreo y reportes.

De este modo, anualmente se solicita a los países miembro que presenten
información sobre 28 indicadores específicos y 8 generales:

-   Existencia de metadatos

-   Conformidad de metadatos

-   Cobertura geográfica de los conjuntos de datos espaciales

-   Conformidad de los conjuntos de datos espaciales

-   Accesibilidad de los metadatos a través de servicios de descubrimiento

-   Accesibilidad de los conjuntos de datos espaciales a través de los servicios
    de visualización y de descarga

-   Utilización de los servicios de red

-   Conformidad de los servicios de red

Adicionalmente al reporte anual que elabora INSPIRE con esos datos, también se
requiere, a los Estados de la Unión Europea, información trianual (sobre la que
se elaboran informes descriptivos) correspondiente a:

-   La coordinación de los conjuntos y servicios de datos espaciales y las
    medidas para garantizar la calidad

-   La contribución al funcionamiento y coordinación de la IDE

-   La información sobre el uso de la IDE

-   Los acuerdos de puesta en común de datos

-   Los costos y beneficios

La evaluación de INSPIRE analiza elementos similares a los considerados por
IDERA, relacionados con la aplicación de sus propios estándares, pero lo hace
por medio de reportes y encuestas.

Así, al igual que en la propuesta de IDERA (desarrollada en profundidad más
adelante en el presente documento), además del monitoreo solicita un reporte, y
busca analizar la máxima jerarquía de IDE.

Tiene como ventaja el basarse en marcos legales muy firmes de carácter nacional
y supranacional, cuyo cumplimiento resulta una obligación, mientras que IDERA,
al carecer de un marco legal (no tiene aún una Ley de creación, sino que
funciona como un conjunto de actores y organismos), sólo puede realizar
recomendaciones, de cumplimiento voluntario.

### Reporte de la COGO

El reporte elaborado por la COGO, según Masser (2017), consiste en una
evaluación cualitativa del status y condición de la IDE de los EEUU y de sus
datos.

Cabe recordar que la IDE de EEUU fue creada a partir de una Orden Ejecutiva del
presidente en 1994, por lo que se trata de una experiencia pionera y de
referencia mundial en cuanto al desarrollo de IDE, a la vez que permitió iniciar
el debate sobre la naturaleza de las IDE, su implementación y, en función de
ello, la generación de estándares para la interoperabilidad.

La calificación, desarrollada y aplicada por un consorcio de Organizaciones no
Gubernamentales, busca evaluar hasta qué punto la información geográfica resulta
adecuada y accesible.

Se trata de una metodología de evaluación que, en la presentación de sus
resultados, toma una forma similar a un boletín de calificaciones escolar, en el
que los distintos temas y aspectos se califican con igual escala que las
materias de una currícula educativa.

Así, dichas calificaciones siguen la siguiente escala: A: apto para el futuro;
B: adecuado por ahora; C: requiere atención; D: en riesgo; E: no apto para el
propósito.

De esta forma, previo a sintetizar a la IDE como a un todo, se clasifica, a los
datos en forma temática, en siete grandes grupos:

-   Catastro

-   Elevación

-   Geodesia

-   Unidades gubernamentales

-   Hidrografía

-   Ortoimágenes

-   Transporte

A su vez, en relación con los distintos aspectos a considerar del funcionamiento
de una IDE, evalúa:

-   Capacidad

-   Condición

-   Financiamiento

-   Necesidades futuras

-   Operación y mantenimiento

-   Uso público

-   Resiliencia

En base a los resultados de cada uno de estos siete aspectos se obtiene,
asimismo, un valor global.

A diferencia de la evaluación desarrollada por IDERA, el Reporte del COGO asigna
una calificación cualitativa para analizar si los datos correspondientes a
determinado tema necesitan revisarse o no y si la IDE posee las herramientas
necesarias para su buen funcionamiento, a un nivel muy genérico.

También se diferencia de la evaluación de IDERA, y de otras evaluaciones de IDE,
por el hecho de que se trata de un reporte elaborado, exclusivamente, por
organizaciones de profesionales vinculados a las IDE, pero del que no
participan, institucionalmente, las organizaciones estatales con competencia en
el tema ni las Universidades que investigan esta cuestión.

### Evaluación de eSDI-Net+

La evaluación desarrollada por eSDI-Net+ para las IDE subnacionales europeas,
según los trabajos de Rix, Fast, Masser, Salgé y Vico (2011) y Jiménez-Calderón,
Yépez-Campoverde y Vázquez-Hoehne (2017), pone foco en cuatro aspectos
centrales: tecnología y cumplimiento INSPIRE, sostenibilidad organizacional,
participación de usuarios y temática IDE.

Este enfoque se validó en un estudio que contó con la participación de diversos
actores de 200 IDE de 26 países de Europa, cofinanciado por el programa
eContent*plus* de la Comisión Europea y coordinado por la Universidad Técnica de
Darmstadt, Alemania.

Define las IDE a evaluar hasta un nivel administrativo mínimo, que incluye
regiones chicas para diagnósticos específicos, hechos por la Comisión Europea,
pero no incorpora a las IDE de los gobiernos locales, a diferencia de la
evaluación de IDERA que considera que una IDE municipal puede ser contemplada
como de máxima jerarquía y, por ende, resultar pasible de ser evaluada.

Un total de 32 indicadores son aplicados por eSDI-Net+:

-   Capacidad

-   Seis indicadores cuantitativos: metadatos, capas WMS y conjuntos de datos

-   Siete indicadores cualitativos: precisión y calidad, promoción de los
    servicios de valor agregado, disponibilidad de Geoportal, de servicios de
    localización y visualización, de un catálogo de metadatos con motor de
    búsqueda, y de Mapa interactivo para funciones de vista

-   Siete indicadores de cooperación y subsidiariedad: responsables de la
    elaboración y aplicación IDE, manejo de los costos, información sobre
    estructura y creación de redes y provisión de formación y capacitación de
    usuarios

-   Cuatro indicadores de sostenibilidad: impacto socioeconómico, modelo de
    negocio sostenible, presupuesto específico, condición jurídica y aspectos
    legales

-   Ocho indicadores de usuarios y usabilidad: multilingüismo, necesidades de
    los usuarios, nivel de acceso, usuarios finales del sector público y
    privado, consideración del uso, satisfacción del usuario y disponibilidad de
    las mediciones de rendimiento del servicio.

Se basa en cuestionarios y entrevistas para recopilar la información. Planteando
un cuestionario que conforma la tarjeta de identificación de la IDE, similar al
cuestionario propuesto por IDERA en forma de reporte anual para evaluar la
evolución de cada IDE.

eSDI-Net+ e IDERA plantean la misma forma de recopilar información, con un
procedimiento que incluye entrevistas, información publicada por el mismo
organismo en el sitio de la IDE y otros documentos que se encuentren online
sobre la IDE.

De la misma forma en que desde IDERA se planteó tener en cuenta las
particularidades de cada caso y acompañar las variables con un seguimiento
personalizado a través del formulario de informe anual, eSDI-Net+ remarca el
hecho de que las experiencias IDE difieren mucho unas de otras, siendo necesario
entender qué fortalezas y debilidades tiene cada una.

Además, plantea el uso de una plataforma para la publicación de los datos de una
autoevaluación, equivalente al informe anual de la evaluación IDERA, que busca
recopilar los datos de las IDE existentes y su estado, pero además permite a las
IDE conocerse entre sí.

Ambas iniciativas de evaluación destacan la importancia de construir esta base
de datos, para conocer la diversidad y actividades IDE que existen, en un caso
en la Unión Europea y en el otro en Argentina.

También existe coincidencia en el reconocimiento de la utilidad de esta forma de
evaluar (análisis del grado en que el funcionamiento de las IDE resulta conforme
a las normas), como una forma de autoverificación de debilidades y fortalezas.
Además, en estas dos evaluaciones, existe conciencia acerca de su potencialidad
en tanto fuente de actividades de capacitación.

Es interesante ver que para eSDI-Net+ fue útil visibilizar, dentro de las doce
mejores IDE, las que son excelentes en buenas prácticas en las categorías
tecnología, organizacional, usuario y temáticas.

Es importante tener en cuenta los procedimientos y el análisis de experiencias
que hace eSDI-Net+, que van en línea con lo planteado originalmente para la
evaluación de IDERA. Esto es, en primer lugar, la necesidad de que, en IDERA,
cada IDE se haga responsable de actualizar este informe o ficha con sus datos y
estado de situación. Y, en segundo término, que IDERA administre la base de
datos con toda la información, pudiendo cruzarla y sacar conclusiones al
respecto, además de convertirla en una fuente de información para el sitio web.

Por otro lado, en base a esta experiencia, resulta importante replantear las
variables de la evaluación de IDERA, dado que hay una necesidad de consenso en
la comunidad al respecto de qué recomendaciones de IDERA resultan básicas para
ser considerada IDE y cuáles deben ser tomadas en cuenta como buenas prácticas,
que permitirían certificar, desde la IDE nacional, un nivel superior de
interoperabilidad.

### Evaluación de UN-GGIM:Américas

La evaluación del capítulo americano de UN-GGIM para todas las IDE nacionales
del continente, descrita en Jiménez-Calderón, Yépez-Campoverde y Vázquez-Hoehne
(2017), se concentra en indicadores binarios, generales y específicos, referidos
a los arreglos institucionales, a los conjuntos de datos y al impacto.

El carácter binario de los indicadores obedece al hecho de que los mismos
asignan un valor de 1 a los casos en que se cumple con la condición prevista y
un valor de 0 cuando no se cumple. A su vez, el cumplimiento o no de tales
condiciones previstas en los respectivos indicadores no es verificado en forma
directa, sino que surge de encuestas realizadas anualmente en los distintos
países de la región.

UN-GGIM:Américas considera 16 indicadores generales y 55 indicadores específicos
relacionados a:

-   Los arreglos institucionales (marco legal y su aplicación, políticas de la
    iniciativa IDE y su alcance, modelo de financiamiento de la IDE y su
    alcance, modelo de retorno de la inversión de la IDE)

-   Los conjuntos de datos (conjuntos de datos o sus metadatos disponibles desde
    la IDE, servicios accesibles desde la IDE, implementación de medición del
    uso de los servicios de la IDE)

-   El impacto (evaluación o monitoreo del impacto económico/social de la IDE,
    tipo de impacto medido, alcance sectorial y/o territorial del mismo y de su
    medición).

Dado que los resultados se limitan a mostrar, a lo largo del tiempo, la
variación en el número de países de la región que cumplen o no con cada
indicador, se trataría más de un conjunto de estadísticas que de una evaluación.
El hecho de que se consignen, asimismo, buenas prácticas e historias exitosas
documentadas, tampoco alcanza para considerar a esta experiencia como una
evaluación.

De acuerdo a los indicadores priorizados por UN-GGIM:Américas se advierte que
los mismos coinciden parcialmente con los considerados en la evaluación de
IDERA. En particular, la mayor parte de los indicadores referidos a los
conjuntos de datos y algunos correspondientes a los arreglos institucionales
presentan dicha coincidencia. Mientras que, ni los indicadores de impacto ni
(dentro de los que forman parte de los arreglos institucionales) los de
financiamiento son tenidos en cuenta en la evaluación desarrollada por IDERA.

### Índice de aptitud Clearinghouse

El Índice de aptitud Clearinghouse, según analiza Bezos (2014), se basa en una
semaforización de la calidad y funcionalidad de una IDE, entendida como un
centro de datos espaciales.

Así, en primer lugar, se seleccionaron quince características a tener en cuenta
para evaluar una IDE:

-   Proveedores

-   Visitantes

-   Referencias web

-   Idiomas

-   Actualizaciones de la web

-   Accesibilidad de los datos

-   Conjuntos de datos

-   Actualización de los conjuntos de datos

-   Arquitectura de red descentralizada

-   Servicios de visualización

-   Mecanismos (alternativas) para la búsqueda

-   Uso de los mapas para la búsqueda

-   Registro de acceso

-   Continuidad de la financiación

-   Estándar de metadatos

El principio general fue que estos indicadores resulten fáciles de medir y que
sean de carácter objetivo

Luego, en base a la opinión de un conjunto amplio de profesionales en la
materia, se estableció una clasificación en tres clases para cada indicador (de
allí la similitud con un semáforo de tres colores) y las respectivas
ponderaciones para cada uno de los quince indicadores, a aplicarse para la
elaboración de un índice que sintetice la situación general de la IDE.

Si bien algunos indicadores pueden resultar similares a los utilizados por
IDERA, el hecho de que la selección de los indicadores haya sido realizada sin
una perspectiva que considera las particularidades de nuestra región y de
nuestro país, así como el sistema mismo de semaforización, no proveen una imagen
que nos permita caracterizar a la IDE de acuerdo a los estándares desarrollados
en los últimos años en Argentina.

Esta experiencia vuelve a remarcar la necesidad de un análisis con el conjunto
de la comunidad, considerando tanto a los diversos actores clave institucionales
como a los académicos.

### Índice de Alistamiento

El Índice de Alistamiento, desarrollado en Bezos (2014) y en Delgado Fernández y
Crompvoets (2007) en el marco del proyecto CYTED-IDEDES 606PI0294 “Evaluación y
potenciación de las IDE para el desarrollo sostenible en América Latina y el
Caribe”, con el apoyo de un Proyecto de la Universidad de Wageningen de Holanda
dedicado a evaluación de iniciativas IDE en el mundo (RGI-005), no apunta tanto
a establecer como funciona efectivamente una IDE, como a dar cuenta de cuán
preparado está un país para armar una IDE y para mantenerla operando en forma
sostenida.

Entiende a cada IDE como una herramienta para compartir información geográfica
al interior de una comunidad que, por su escala, puede ser global, nacional,
regional o local. A su vez, considera como IDE a los casos que tienen un marco
legal, catastro digital y datos básicos y fundamentales definidos, mientras que
al resto de las experiencias las clasifica como iniciativas semejantes o de
apoyo.

Está estructurado en base a distintos tipos de factores: organizativos, de
información, de personas, de tecnología y de recursos financieros.

-   Factores organizativos: la visión, el liderazgo institucional y el marco
    legal (en tanto cristalización de acuerdos institucionales)

-   Factores de Información: la cartografía digital y los metadatos disponibles.

-   Factores de recursos humanos: el capital humano con que se cuenta para la
    IDE, la educación y cultura en el país sobre IDE y el liderazgo individual

-   Factores de tecnología: la conectividad web, la infraestructura de
    telecomunicaciones, la disponibilidad de software geoespacial, los
    desarrollos propios y la cultura de código abierto

-   Factores de recursos financieros: los fondos del gobierno central (nacional)
    dedicados a la IDE, las políticas de retorno de esa inversión y la actividad
    del sector privado.

La forma en que estos distintos factores logran conformar un único índice no es
a través de una función polinómica que aplica ponderadores a cada categoría,
como es habitual en la mayor parte de las evaluaciones de IDE (incluso en la de
IDERA), sino mediante un modelo matemático basado en la lógica difusa.

Esta mayor complejidad técnica, sumada a que el Índice de Alistamiento ha sido
concebido para aplicarse a las IDE a nivel de un país en su conjunto y a que el
mismo se ha generado y validado desde el ámbito académico y no desde la
comunidad de actores que integran una o más IDE (a diferencia de la evaluación
que desarrolla IDERA), permite identificarlo como un análisis teórico de
factores cualitativos que sólo se pueden responder a través de entrevistas e
informes y da cuenta de que este índice apunta más a comparar experiencias
nacionales para su estudio científico que a enfocarse en la solución de las
debilidades encontradas, ya que simplemente se queda en la descripción.

Al igual que en la evaluación desarrollada por IDERA, el Índice de Alistamiento
remarca la importancia de tener en cuenta las particularidades de las distintas
experiencias de implementaciones de IDE y el hecho de que las IDE no son
estáticas, sino que se desarrollan en procesos dinámicos que encuentran su
validez en las especificidades de cada país y de los estándares a medida que se
van desarrollando a nivel global.

Entiende, así, que Iberoamérica tiene distintas necesidades y problemáticas,
como son el acceso a financiamiento o la aplicación efectiva de complejos marcos
legales y eso afecta en cómo se encaran las iniciativas IDE. A esto mismo apunta
IDERA con la solicitud de un informe anual, que no solo dé cuenta del estado de
cada IDE y permita caracterizarla, sino que además genere la posibilidad de
cuestionar permanentemente la evaluación y los estándares que IDERA recomienda,
llevando a los actores a actualizarse y a adaptarse constantemente, función
básica de una IDE, como es la de seguir el camino de la innovación y mantenerse
interoperable a nivel global.

### Evaluación de Gideon

En el marco de GIDEON, se estableció una evaluación multicriterio orientada a
objetivos, tal como se analiza en Grus et al (2011), en Castelein y Manso
Callejo (2010) y en Jiménez-Calderón, Yépez-Campoverde y Vázquez-Hoehne (2017).

Tal evaluación establece una serie de fases que incluyen la construcción de las
variables, la determinación de cuál es el propósito de la evaluación, el punto
de vista desde el que se evalúa y la aplicación y resultados de la evaluación.

La pregunta central de la evaluación es en qué grado se han logrado los
objetivos de la IDE. Para responder a ello se construyen una serie de
indicadores adecuados para esa IDE. Tales indicadores surgen de una priorización
realizada en talleres con la participación de actores clave de la IDE, que
permite seleccionar los más adecuados y operacionales para poder hacer la
evaluación.

Este proceso, dado el gran peso del factor humano en el mismo y el carácter,
eminentemente cualitativo de los indicadores utilizados, implicó una serie de
fuertes tensiones y disidencias que se extendieron, incluso, hasta la instancia
misma de presentación de resultados de la evaluación.

Más allá de que la evaluación de IDERA esté diseñada para aplicarse a las IDE
que la componen y que GIDEON evalúe a la IDE nacional holandesa en su conjunto,
es válido señalar que, a diferencia de lo que hace IDERA, en la IDE de Holanda
no se evalúan los geoservicios web o aspectos técnicos de la publicación de
información geográfica. Asimismo, al contrario que en IDERA, en el marco de
GIDEON la evaluación no permite arribar a un resultado sintético que refleje a
la IDE en su conjunto, sino que solamente ofrece una visión de los resultados
correspondientes a cada uno de sus cuatro objetivos por separado.

Estos cuatro objetivos contemplan un total de doce indicadores.

-   Objetivo de uso por parte del público y las empresas de la información
    geográfica: visitantes, conjuntos de datos y servicios, uso del visualizador
    y descargas

-   Objetivo de capacidad de las empresas para agregar valor económico a esa
    información geográfica del gobierno: información sobre condiciones de uso,
    conjuntos de datos disponibles sin restricción y volumen del negocio de la
    información geográfica

-   Objetivo de uso de esa información en los procesos de trabajo y servicios
    del gobierno: nivel de cooperación en GIDEON y uso de la información en los
    procesos de gobierno electrónico

-   Objetivo de colaboración de gobiernos, empresas y universidades en el
    continuo desarrollo y mejora de la IDE: eventos de geoinformación, vacantes
    en el sector de la geoinformación, gasto privado en la investigación y
    desarrollo de geoinformación, valor del sector de investigación en
    geoinformación

En términos de implementación, las deficiencias de la normalización de los
procesos de recolección de datos para la evaluación podrían afectar la exactitud
de los mismos. También resulta discutible la pertinencia de dichos datos para
evaluar los objetivos propuestos.

La necesidad de que algunas mediciones se hagan como tendencias a lo largo del
tiempo y el elevado costo del relevamiento de información cualitativa también
surgen como aspectos a tener en cuenta de esta evaluación, al igual que en la de
IDERA.

Como cuestiones valiosas, la evaluación de GIDEON resalta que las IDE de
distintas jurisdicciones pueden tener, además de objetivos generales (como la
mejora en la toma de decisiones), objetivos más específicos y plantea la
necesidad de ampliar el espectro de la evaluación a objetivos genéricos y
amplios y a objetivos específicos y acotados.

Como cuestión valiosa se destaca que GIDEON, a través de una encuesta, analiza
la evaluación implementada, la selección de variables y que estas se ajusten a
los objetivos de la IDE para que sean representativas, objetivas y consistentes.

### Evaluación de la PSDI

La evaluación de la PSDI, analizada en Zwirowicz-Rutkowska (2017), pone el foco
en el retorno de la inversión que se realiza en una IDE.

En cuanto a su implementación, realiza encuestas a actores clave y utiliza
estadísticas de normalización de datos, método que hace que los resultados
tengan que ser validados a través del cálculo del desvío standard, dada la falta
de homogeneidad de lo que se evalúa.

Un hallazgo interesante de la evaluación es la descripción de cómo la calidad de
la información afecta la utilidad de los sets de Información Geográfica para los
profesionales y el impacto de la IDE en los procesos de trabajo. Aunque esta
evaluación no logra identificar las causas del incumplimiento de los objetivos,
sí permite desarrollar algunas recomendaciones.

Así, la evaluación aplicada a la PSDI se concentra en la eficacia entendida como
la performance de las tareas de los usuarios, la atención a sus necesidades y la
consideración de la IDE a través de sus componentes en términos de utilidad,
accesibilidad y usabilidad; además del cumplimiento de objetivos de negocios y
organizacionales.

Va más allá del planteo que se hace IDERA, donde esta utilidad, accesibilidad y
usabilidad se alcanza a través del cumplimiento de los estándares y
recomendaciones específicamente. Sin perjuicio de ello, en las variables que
plantea la evaluación de la PSDI, evalúa la calidad de la información y el
soporte provisto, a través de la exactitud temática, completitud, resolución
espacial, validez temporal y exactitud posicional; además del formato de
distribución y linaje.

También en contraste con IDERA, señala la importancia de la ayuda y los manuales
de usuario. En las otras tres categorías (procesos de uso, performance de los
usuarios institucionales y alineamiento estratégico e impacto en los negocios de
los usuarios empresariales) va a evaluar no tanto lo expuesto por la IDE como la
impresión de los usuarios, en su rol de tomadores de decisiones.

En contrapartida, al igual que IDERA, la evaluación de la PSDI ve a la IDE como
un único proyecto a analizar, no haciendo foco en sus distintas partes sino en
la visión global que se percibe desde fuera de la misma. Así, en un primer
nivel, muestra los pilares, categorías o dominios de evaluación con su esquema
de peso identificado. En segundo término, considera a los indicadores agrupados
por cada uno de esos pilares, categorías o dominios. En tercer lugar, establece
un esquema de peso o calificación para estos indicadores. Y, finalmente, da
cuenta de los resultados de la evaluación, expresados como puntajes para cada
indicador, luego para cada pilar y, por último, como un total para el proyecto
en su conjunto, con sus correspondientes conclusiones.

### Evaluación de la IDEC

La evaluación de lDEC, según Guimet y Colomer (2010), Castelein y Manso Callejo
(2010) y Jiménez-Calderón, Yépez-Campoverde y Vázquez-Hoehne (2017), se centra
en una serie de indicadores de oferta y de demanda de servicios de la IDE.

Se trata de una evaluación periódica (anual), de tipo horizontal, esto es, que
busca medir el funcionamiento de una misma IDE (en este caso la de Cataluña) a
lo largo del tiempo. Las ponderaciones de los veintidós indicadores que componen
el índice han sido establecidas según un acuerdo de la comunidad de actores de
la IDEC.

Estos indicadores corresponden a:

-   Recursos disponibles: metadatos, WMS, WFS, geoservicios, capas, percepción
    de usabilidad por parte de los usuarios

-   Participantes: entidades que aportan metadatos, WMS y que participan en IDE
    temáticas

-   Utilización: accesos a IDEC, a visor local, entidades registradas para
    geoservicios, usuarios y descargas de metadatos, entidades y terceros usando
    recursos de la IDEC

-   Cumplimiento de la ley: departamentos/organismos y municipios que publican
    metadatos y facilitan acceso a WMS)

-   Otros: actividades sobre armonización de la política de datos, armonización
    de los datos y formación y difusión)

Al igual que en la evaluación de IDERA, en la de la IDEC los distintos
indicadores toman un valor que corresponde al grado de cumplimiento respecto a
un determinado objetivo. Luego, a cada uno de los indicadores, se le aplica la
ponderación que la propia comunidad de actores le ha asignado, para arribar a un
índice sintético, que dé cuenta del grado global en que la IDE se asemeja a la
visión objetivo que se ha planteado.

En contrapartida, a diferencia de la evaluación de IDERA, que se aplica a cada
IDE de máxima jerarquía que la integra, la IDEC se considera en su conjunto a la
hora de ser evaluada.

En la misma línea, si bien para la IDEC, al igual que para IDERA, se evalúa la
oferta de datos y servicios, en el caso catalán, adicionalmente, se tiene en
cuenta la demanda de los mismos y las actividades de armonización, de formación
y de difusión que realiza la propia IDE.
